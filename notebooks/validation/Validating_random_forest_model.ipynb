{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "Fg1hB7z4FMN2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, precision_recall_curve\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtFXUo94Fbaf",
        "outputId": "43e1a5ba-1a96-4d99-a396-a0112e71a982"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_FILE_PATH = '/content/drive/MyDrive/Colab Notebooks/Final Project'\n",
        "print(os.listdir(BASE_FILE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS1xIM_GFdJj",
        "outputId": "bf868ad2-3060-40c3-f5d6-01ff7e57a918"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Keys', 'Setting up connection with Git-Hub.ipynb', 'entries.csv', 'summoner_details.csv', 'updated_dataset.csv', 'filtered_dataset.csv', 'filtered_dataset.gsheet', 'filtered_+30_matches_dataset.csv', 'EDA.ipynb', 'merged_dataset.csv', 'Merging match with entries and classifying accounts.ipynb', 'merged_dataset.gsheet', 'Feature engineering and cleaning vol 1.ipynb', 'dataset_after_normalization.csv', 'keepign only win feature .ipynb', 'Models without data normalization.ipynb', 'Normalization_Parameters.csv', 'Normalization_Parameters_by_Team_Position.csv', 'summoner_ids_used_in_model.csv', 'gbm_model.pkl', 'train_df.csv', 'test_df.csv', 'validation_df.csv', 'processed_train_df.csv', 'Normalization_Parameters_by_Game_Mode.csv', 'processed_test_df.csv', 'random_forest_model.pkl', 'processed_validation_df.csv', 'scaler.pkl']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_df = pd.read_csv(os.path.join(BASE_FILE_PATH, 'processed_validation_df.csv'))\n",
        "#get the scaler file\n",
        "with open(os.path.join(BASE_FILE_PATH, 'scaler.pkl'), 'rb') as f:\n",
        "    scaler = pickle.load(f)"
      ],
      "metadata": {
        "id": "L7rTai3AFpbx"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open the pkl gbm_model that is in the BASE_FILE_PATH directory\n",
        "\n",
        "with open(os.path.join(BASE_FILE_PATH, 'random_forest_model.pkl'), 'rb') as f:\n",
        "    random_forest_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "c8ym3yOFGHNs"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(df, model, scaler, features_col, actual_col='binary_time_group'):\n",
        "    \"\"\"\n",
        "    Evaluates the model predictions against actual labels on a DataFrame and updates the DataFrame with predictions.\n",
        "    \"\"\"\n",
        "    # Extracting the features and actual labels\n",
        "    X = df[features_col]\n",
        "    y_actual = df[actual_col]\n",
        "\n",
        "    # Debugging: print feature names to check if they match\n",
        "    print(\"Features used for scaling:\", scaler.feature_names_in_)\n",
        "    print(\"Features from dataframe:\", X.columns.tolist())\n",
        "\n",
        "    # Reorder features to match the training order\n",
        "    X = X[scaler.feature_names_in_]\n",
        "\n",
        "    # Scaling the features\n",
        "    X_scaled = scaler.transform(X)\n",
        "\n",
        "    # Predicting using the model\n",
        "    predictions = model.predict(X_scaled)\n",
        "\n",
        "    # Determining if each prediction is correct\n",
        "    df['prediction'] = ['Correct' if act == pred else 'Incorrect' for act, pred in zip(y_actual, predictions)]\n",
        "\n",
        "    # Summary of predictions\n",
        "    correct_count = df['prediction'].value_counts().get('Correct', 0)\n",
        "    total = len(predictions)\n",
        "    accuracy = correct_count / total\n",
        "\n",
        "    # Count the correct predictions by actual status\n",
        "    status_correct_counts = df[df['prediction'] == 'Correct']['binary_time_group'].value_counts()\n",
        "    active_correct = status_correct_counts.get('Active', 0)\n",
        "    inactive_correct = status_correct_counts.get('Inactive', 0)\n",
        "\n",
        "    print(f\"Total Correct Predictions: {correct_count}/{total}\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"Correct Active Predictions: {active_correct}\")\n",
        "    print(f\"Correct Inactive Predictions: {inactive_correct}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage assuming you have a DataFrame `validation_df` and a trained model `random_forest_model`:\n",
        "features_for_prediction = list(scaler.feature_names_in_)  # This ensures the feature order is correct\n",
        "updated_validation_df = evaluate_predictions(validation_df, random_forest_model, scaler, features_for_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWehZiZ5GACs",
        "outputId": "a3e37aeb-41ea-42c2-c93e-20dab00874f8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features used for scaling: ['deaths_normalized_late' 'kills_normalized_late'\n",
            " 'assists_normalized_late' 'game_duration_normalized_late'\n",
            " 'total_minions_killed_normalized_late' 'gold_earned_normalized_late'\n",
            " 'total_damage_dealt_normalized_late' 'total_damage_taken_normalized_late'\n",
            " 'deaths_normalized_mid' 'kills_normalized_mid' 'assists_normalized_mid'\n",
            " 'game_duration_normalized_mid' 'total_minions_killed_normalized_mid'\n",
            " 'gold_earned_normalized_mid' 'total_damage_dealt_normalized_mid'\n",
            " 'total_damage_taken_normalized_mid' 'deaths_normalized_initial'\n",
            " 'kills_normalized_initial' 'assists_normalized_initial'\n",
            " 'game_duration_normalized_initial']\n",
            "Features from dataframe: ['deaths_normalized_late', 'kills_normalized_late', 'assists_normalized_late', 'game_duration_normalized_late', 'total_minions_killed_normalized_late', 'gold_earned_normalized_late', 'total_damage_dealt_normalized_late', 'total_damage_taken_normalized_late', 'deaths_normalized_mid', 'kills_normalized_mid', 'assists_normalized_mid', 'game_duration_normalized_mid', 'total_minions_killed_normalized_mid', 'gold_earned_normalized_mid', 'total_damage_dealt_normalized_mid', 'total_damage_taken_normalized_mid', 'deaths_normalized_initial', 'kills_normalized_initial', 'assists_normalized_initial', 'game_duration_normalized_initial']\n",
            "Total Correct Predictions: 782/874\n",
            "Accuracy: 0.89\n",
            "Correct Active Predictions: 526\n",
            "Correct Inactive Predictions: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_validation_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvtkUYrhHHt3",
        "outputId": "af6bd415-ad01-4243-f6cf-a68c6649d3f9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 874 entries, 0 to 873\n",
            "Data columns (total 23 columns):\n",
            " #   Column                                Non-Null Count  Dtype  \n",
            "---  ------                                --------------  -----  \n",
            " 0   deaths_normalized_late                874 non-null    float64\n",
            " 1   kills_normalized_late                 874 non-null    float64\n",
            " 2   assists_normalized_late               874 non-null    float64\n",
            " 3   game_duration_normalized_late         874 non-null    float64\n",
            " 4   total_minions_killed_normalized_late  874 non-null    float64\n",
            " 5   gold_earned_normalized_late           874 non-null    float64\n",
            " 6   total_damage_dealt_normalized_late    874 non-null    float64\n",
            " 7   total_damage_taken_normalized_late    874 non-null    float64\n",
            " 8   deaths_normalized_mid                 874 non-null    float64\n",
            " 9   kills_normalized_mid                  874 non-null    float64\n",
            " 10  assists_normalized_mid                874 non-null    float64\n",
            " 11  game_duration_normalized_mid          874 non-null    float64\n",
            " 12  total_minions_killed_normalized_mid   874 non-null    float64\n",
            " 13  gold_earned_normalized_mid            874 non-null    float64\n",
            " 14  total_damage_dealt_normalized_mid     874 non-null    float64\n",
            " 15  total_damage_taken_normalized_mid     874 non-null    float64\n",
            " 16  deaths_normalized_initial             874 non-null    float64\n",
            " 17  kills_normalized_initial              874 non-null    float64\n",
            " 18  assists_normalized_initial            874 non-null    float64\n",
            " 19  game_duration_normalized_initial      874 non-null    float64\n",
            " 20  binary_time_group                     874 non-null    object \n",
            " 21  summoner_id                           874 non-null    object \n",
            " 22  prediction                            874 non-null    object \n",
            "dtypes: float64(20), object(3)\n",
            "memory usage: 157.2+ KB\n"
          ]
        }
      ]
    }
  ]
}