{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rank  tier  match_count  count\n",
      "0    II  GOLD           22      1\n",
      "1    II  GOLD           25      1\n",
      "2    II  GOLD           31      1\n",
      "3    II  GOLD           47      1\n",
      "4    II  GOLD           59     20\n",
      "5   III  GOLD           14      1\n",
      "6   III  GOLD           18      1\n",
      "7   III  GOLD           23      1\n",
      "8   III  GOLD           33      1\n",
      "9   III  GOLD           34      1\n",
      "10  III  GOLD           36      1\n",
      "11  III  GOLD           38      1\n",
      "12  III  GOLD           39      1\n",
      "13  III  GOLD           52      1\n",
      "14  III  GOLD           53      1\n",
      "15  III  GOLD           59     24\n",
      "16   IV  GOLD            9      2\n",
      "17   IV  GOLD           22      1\n",
      "18   IV  GOLD           59     26\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "match_ids_csv = '../data/raw/match_ids.csv'\n",
    "summoner_details_csv = '../data/raw/summoner_details.csv'\n",
    "entries_csv = '../data/raw/entries.csv'\n",
    "\n",
    "# Ensure all CSV files exist\n",
    "for file in [match_ids_csv, summoner_details_csv, entries_csv]:\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"{file} not found.\")\n",
    "        exit()\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "summoner_details_df = pd.read_csv(summoner_details_csv)\n",
    "entries_df = pd.read_csv(entries_csv)\n",
    "\n",
    "# Group match_ids by puuid to count the number of matches per account\n",
    "matches_per_puuid = match_ids_df.groupby('puuid')['match_id'].nunique().reset_index(name='match_count')\n",
    "\n",
    "# Merge with summoner_details to get summoner_id\n",
    "matches_per_puuid = pd.merge(matches_per_puuid, summoner_details_df[['puuid', 'summoner_id']], on='puuid', how='left')\n",
    "\n",
    "# Merge with entries to get the rank and tier\n",
    "matches_per_puuid = pd.merge(matches_per_puuid, entries_df[['summoner_id', 'rank', 'tier']], on='summoner_id', how='left')\n",
    "\n",
    "# Group by rank, tier, and number of matches\n",
    "grouped_matches = matches_per_puuid.groupby(['rank', 'tier', 'match_count']).size().reset_index(name='count')\n",
    "\n",
    "# Display the grouped results\n",
    "print(grouped_matches)\n",
    "\n",
    "# Optionally, save the grouped results to a CSV file\n",
    "grouped_matches.to_csv('../data/processed/grouped_matches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                puuid  match_count  \\\n",
      "2   2L5tVwrIogGyB7WcXKM5wSvqjO-M2MXlNkEprtMmqlR5cU...           59   \n",
      "3   2qkoaHrz1dWku8VAgEjblYaprBEqgewXzamCf1QdqyqjcM...           59   \n",
      "4   3jgt0zNs-YzYH703f6emUUj6K8vkeupG_8ZU1DuGsv0y8_...           59   \n",
      "5   4K8FJPOjTSTa9UlEU6WvflI04u5Hk20K0-qEz0bQbePIEK...           59   \n",
      "6   5IMEoc21qtIT7_uiKbtq8UdyEPL9LC7eRdMuMY-_w1qora...           59   \n",
      "..                                                ...          ...   \n",
      "82  ws72IxAdAs2WU0M6K7nCO8Yek9E3SEJHI0NFjSYLYzcT0h...           59   \n",
      "83  xA1JKB2ujC5fpJS5Y6S_tqEq6y4tU-VA2zcNtuzUTRpFTw...           59   \n",
      "84  xM-QykIXsWAJte5zqS357lnxtjqTATM3ixfS1kgTs5dHS9...           59   \n",
      "85  yX-c1obh0Ax4uu-vbQQMSFjOH-rXykTin890_INSN4zHFv...           59   \n",
      "86  zjVtYCLC5GkgrSq_05S0OB870najP6rd772MhlUmCgQtEH...           59   \n",
      "\n",
      "                                         summoner_id rank  tier  \n",
      "2   9lAqeClj-g6evDTejZLYCy08QbqOD8sF4wn4fW6pB1xCA5XZ   IV  GOLD  \n",
      "3       gYBnbZg_XiGfW6bdIm1zJFhLGRykhe8peJ0HjgNCsi-X   II  GOLD  \n",
      "4   Bnf6wnVzqgtMXIsmPSMFDSUJ2-HTbz0aNX1or-DD7ZGjOYu9   IV  GOLD  \n",
      "5    5Mw9gFSDnfvCOtQH-mMOpsrHg5f-8KnU5z88CdHirFQHYv4   II  GOLD  \n",
      "6    6Mk1xKimGiFOj-fCCSLfRC8y774TZzzXcrsQX8MpRNOEUGY   II  GOLD  \n",
      "..                                               ...  ...   ...  \n",
      "82  qDQVURp1cxWZusSw6PeDQj510qj497Rk62gkCuozrtwrxHCI   IV  GOLD  \n",
      "83  Byh4ydtUqpwfM79yfPEg0XQktCLnZ2-BbV24VCDkPa-iSutk   IV  GOLD  \n",
      "84  7vFq_4C2UA2P3vtDPCcu8-k1lGWu3dIm1YGKxzllCNGwDd0Q   IV  GOLD  \n",
      "85  9ZVh7cXZcpzXNxTkK8RKbplWhjMUWdW9vRbic4mkMS__B5OB  III  GOLD  \n",
      "86  96pejZej6KP6g5Vpky9lHhCkWCxzsLs4qOtI0C8muk125DrP   IV  GOLD  \n",
      "\n",
      "[70 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the accounts that have exactly 59 matches\n",
    "filtered_accounts = matches_per_puuid[matches_per_puuid['match_count'] == 59]\n",
    "\n",
    "# Display the filtered results\n",
    "print(filtered_accounts)\n",
    "\n",
    "# Optionally, save the filtered results to a CSV file for further use\n",
    "filtered_accounts.to_csv('../data/processed/filtered_accounts_with_59_matches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               league_id       queue_type  tier rank  \\\n",
      "0   71e2cc57-96f0-4c32-a9a6-a247d322eaf5  RANKED_SOLO_5x5  GOLD   II   \n",
      "2   75bb654e-0516-4de6-aa10-bf48bc378f8f  RANKED_SOLO_5x5  GOLD   II   \n",
      "3   3becfc0f-c27e-4311-95ac-94d09932fd01  RANKED_SOLO_5x5  GOLD   II   \n",
      "4   2610e86e-1f23-411f-8cc7-82856ebf934a  RANKED_SOLO_5x5  GOLD   II   \n",
      "6   34bd5cf8-47da-44d3-8d73-a40eaddf54cc  RANKED_SOLO_5x5  GOLD   II   \n",
      "..                                   ...              ...   ...  ...   \n",
      "80  b33f1937-be10-4488-8786-fd19ff68a8e5  RANKED_SOLO_5x5  GOLD   IV   \n",
      "81  6b4558e6-bf86-4ab3-b6a6-16eb2a52c44b  RANKED_SOLO_5x5  GOLD   IV   \n",
      "82  47f8c8c4-2470-4d5e-9239-8d4bbd6a7527  RANKED_SOLO_5x5  GOLD   IV   \n",
      "83  df46043c-5c85-4c98-aba1-08dd6d2c8de8  RANKED_SOLO_5x5  GOLD   IV   \n",
      "84  0526c5c5-f50f-47c6-b420-caf3b3e92bd1  RANKED_SOLO_5x5  GOLD   IV   \n",
      "\n",
      "                                         summoner_id  league_points  wins  \\\n",
      "0   27e3ppC2YX1YRomMgqPJv3cUmkARZsKL4d-yzlNE0IdIVhqJ             58    63   \n",
      "2   wwpgOwaMA2bAKt0kS1f4qDdwyjYnTh8eO9rY-pJBBp-LJQfs             74    22   \n",
      "3   Cku1lrcFKLTrqUhJDo7jJXEWeQ5YsUlr9TfXXOdOiT5glaYl             52     6   \n",
      "4   hKEZK0BcRbZuKi_jDw8vHAJMuybJAOBoH1Km5Tk5BNilKktl             67    69   \n",
      "6   Cp2DHLhkci3X5Lo65oMJ7nLQj7bYOeElMHgR2H9oyt_8c_tu             85     7   \n",
      "..                                               ...            ...   ...   \n",
      "80  1gxSEEXrY8u1O0JbkU0Pm1WVXOj_BeQa7SgbHUZDSff08Mh4              0     5   \n",
      "81  OV0FkM6PffZ_dQl3ayUMlOAsRwP0xmy0PPK8y0TnHr9Oyofx             73     9   \n",
      "82  _gh7H7ZrCtXjcM-N2XgOjOxooAlvQR0nRo_tMUDXUepClqFs              0    39   \n",
      "83  qDQVURp1cxWZusSw6PeDQj510qj497Rk62gkCuozrtwrxHCI             85    13   \n",
      "84  pv017nrsj-kpLoaqQQi-DNyzwwvWhuQ5ppk7b4hNtJDn_QNc              0     4   \n",
      "\n",
      "    losses  veteran  inactive  fresh_blood  hot_streak  \n",
      "0       56    False     False        False       False  \n",
      "2       18    False     False        False       False  \n",
      "3        3    False     False        False       False  \n",
      "4       73    False     False        False       False  \n",
      "6        4    False     False        False       False  \n",
      "..     ...      ...       ...          ...         ...  \n",
      "80      12    False     False        False       False  \n",
      "81       5    False     False        False       False  \n",
      "82      45    False     False        False       False  \n",
      "83      17    False     False        False       False  \n",
      "84      12    False     False        False       False  \n",
      "\n",
      "[70 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "entries_csv = '../data/raw/entries.csv'\n",
    "match_ids_csv = '../data/raw/match_ids.csv'\n",
    "summoner_details_csv = '../data/raw/summoner_details.csv'\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "entries_df = pd.read_csv(entries_csv)\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "summoner_details_df = pd.read_csv(summoner_details_csv)\n",
    "\n",
    "# Get the summoner_ids of accounts that have exactly 59 matches\n",
    "puuids_with_59_matches = match_ids_df.groupby('puuid')['match_id'].count()\n",
    "puuids_with_59_matches = puuids_with_59_matches[puuids_with_59_matches == 59].index\n",
    "\n",
    "# Get the corresponding summoner_ids from summoner_details.csv\n",
    "summoner_ids_with_59_matches = summoner_details_df[summoner_details_df['puuid'].isin(puuids_with_59_matches)]['summoner_id']\n",
    "\n",
    "# Filter the entries.csv for those summoner_ids\n",
    "filtered_entries = entries_df[entries_df['summoner_id'].isin(summoner_ids_with_59_matches)]\n",
    "\n",
    "# Display the filtered entries DataFrame\n",
    "print(filtered_entries)\n",
    "\n",
    "# Optionally, save the filtered entries to a new CSV file\n",
    "filtered_entries.to_csv('../data/processed/filtered_entries_with_59_matches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended new accounts to ../data/processed/entries.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "entries_csv = '../data/raw/entries.csv'\n",
    "match_ids_csv = '../data/raw/match_ids.csv'\n",
    "summoner_details_csv = '../data/raw/summoner_details.csv'\n",
    "processed_entries_csv = '../data/processed/entries.csv'  # Processed file to append to\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "entries_df = pd.read_csv(entries_csv)\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "summoner_details_df = pd.read_csv(summoner_details_csv)\n",
    "\n",
    "# Get the summoner_ids of accounts that have exactly 59 matches\n",
    "puuids_with_59_matches = match_ids_df.groupby('puuid')['match_id'].count()\n",
    "puuids_with_59_matches = puuids_with_59_matches[puuids_with_59_matches == 59].index\n",
    "\n",
    "# Get the corresponding summoner_ids from summoner_details.csv\n",
    "summoner_ids_with_59_matches = summoner_details_df[summoner_details_df['puuid'].isin(puuids_with_59_matches)]['summoner_id']\n",
    "\n",
    "# Filter the entries.csv for those summoner_ids\n",
    "filtered_entries = entries_df[entries_df['summoner_id'].isin(summoner_ids_with_59_matches)]\n",
    "\n",
    "# Load the existing processed entries CSV file\n",
    "if os.path.exists(processed_entries_csv):\n",
    "    processed_entries_df = pd.read_csv(processed_entries_csv)\n",
    "else:\n",
    "    processed_entries_df = pd.DataFrame(columns=entries_df.columns)  # Create an empty DataFrame if file doesn't exist\n",
    "\n",
    "# Append the new filtered entries to the existing processed entries\n",
    "updated_entries_df = pd.concat([processed_entries_df, filtered_entries]).drop_duplicates(subset='summoner_id')\n",
    "\n",
    "# Save the updated entries DataFrame back to the processed folder\n",
    "updated_entries_df.to_csv(processed_entries_csv, index=False)\n",
    "\n",
    "print(f\"Appended new accounts to {processed_entries_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m processed_entries_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(processed_entries_csv)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Find the groups that need more accounts\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m current_counts \u001b[38;5;241m=\u001b[39m \u001b[43mprocessed_entries_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrank\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m needed_groups \u001b[38;5;241m=\u001b[39m current_counts[(current_counts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100\u001b[39m)]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Step 2: Get the summoner_ids of accounts that have exactly 59 matches\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:9156\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9159\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9162\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_group'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "entries_csv = '../data/raw/entries.csv'\n",
    "match_ids_csv = '../data/raw/match_ids.csv'\n",
    "summoner_details_csv = '../data/raw/summoner_details.csv'\n",
    "processed_entries_csv = '../data/processed/entries.csv'  # Processed file to append to\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "entries_df = pd.read_csv(entries_csv)\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "summoner_details_df = pd.read_csv(summoner_details_csv)\n",
    "processed_entries_df = pd.read_csv(processed_entries_csv)\n",
    "\n",
    "# Step 1: Find the groups that need more accounts\n",
    "current_counts = processed_entries_df.groupby(['rank', 'time_group']).size().reset_index(name='count')\n",
    "needed_groups = current_counts[(current_counts['count'] < 100)]\n",
    "\n",
    "# Step 2: Get the summoner_ids of accounts that have exactly 59 matches\n",
    "puuids_with_59_matches = match_ids_df.groupby('puuid')['match_id'].count()\n",
    "puuids_with_59_matches = puuids_with_59_matches[puuids_with_59_matches == 59].index\n",
    "\n",
    "# Get the corresponding summoner_ids from summoner_details.csv\n",
    "summoner_ids_with_59_matches = summoner_details_df[summoner_details_df['puuid'].isin(puuids_with_59_matches)]['summoner_id']\n",
    "\n",
    "# Step 3: Filter the entries.csv for those summoner_ids\n",
    "filtered_entries = entries_df[entries_df['summoner_id'].isin(summoner_ids_with_59_matches)]\n",
    "\n",
    "# Step 4: Check how many accounts are missing in each group and append only those\n",
    "for _, row in needed_groups.iterrows():\n",
    "    rank = row['rank']\n",
    "    time_group = row['time_group']\n",
    "    current_count = row['count']\n",
    "    missing_count = 100 - current_count\n",
    "    \n",
    "    # Filter accounts in the required rank and time_group\n",
    "    candidates = filtered_entries[(filtered_entries['rank'] == rank) & (filtered_entries['time_group'] == time_group)]\n",
    "    \n",
    "    # Append only the number of missing accounts\n",
    "    if len(candidates) > missing_count:\n",
    "        selected_accounts = candidates.sample(n=missing_count, random_state=42)  # Randomly select the needed accounts\n",
    "    else:\n",
    "        selected_accounts = candidates\n",
    "    \n",
    "    # Append the selected accounts to the processed entries\n",
    "    processed_entries_df = pd.concat([processed_entries_df, selected_accounts]).drop_duplicates(subset='summoner_id')\n",
    "\n",
    "# Step 5: Save the updated entries DataFrame back to the processed folder\n",
    "processed_entries_df.to_csv(processed_entries_csv, index=False)\n",
    "\n",
    "print(f\"Appended the necessary accounts to {processed_entries_csv}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current group counts in the processed file:\n",
      "  rank  count\n",
      "0    I    600\n",
      "1   II    590\n",
      "2  III    595\n",
      "3   IV    591\n",
      "Updated entries saved to ../data/processed/entries.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "processed_entries_csv = '../data/processed/entries.csv'\n",
    "raw_entries_csv = '../data/raw/entries.csv'\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "processed_entries_df = pd.read_csv(processed_entries_csv)\n",
    "raw_entries_df = pd.read_csv(raw_entries_csv)\n",
    "\n",
    "# Step 1: Find the groups that have fewer than 100 accounts in the processed file\n",
    "current_counts = processed_entries_df.groupby(['rank']).size().reset_index(name='count')\n",
    "print(\"Current group counts in the processed file:\")\n",
    "print(current_counts)\n",
    "\n",
    "# The missing counts based on the initial results:\n",
    "missing_counts = {\n",
    "    ('II', 'GOLD'): 10,  # Needs 10 more accounts to reach 100\n",
    "    ('III', 'GOLD'): 5,  # Needs 5 more accounts to reach 100\n",
    "    ('IV', 'GOLD'): 9   # Needs 9 more accounts to reach 100\n",
    "}\n",
    "\n",
    "# Step 2: Filter raw entries based on the missing accounts\n",
    "new_entries_to_add = pd.DataFrame()\n",
    "\n",
    "for (rank, tier), missing_count in missing_counts.items():\n",
    "    potential_accounts = raw_entries_df[(raw_entries_df['rank'] == rank) & (raw_entries_df['tier'] == tier)]\n",
    "    \n",
    "    # Check if there are enough accounts to add\n",
    "    if len(potential_accounts) >= missing_count:\n",
    "        selected_accounts = potential_accounts.sample(n=missing_count, random_state=1)\n",
    "    else:\n",
    "        selected_accounts = potential_accounts  # Add all if not enough\n",
    "    \n",
    "    new_entries_to_add = pd.concat([new_entries_to_add, selected_accounts])\n",
    "\n",
    "# Step 3: Append the new accounts to the processed entries DataFrame\n",
    "final_entries_df = pd.concat([processed_entries_df, new_entries_to_add]).drop_duplicates(subset='summoner_id')\n",
    "\n",
    "# Step 4: Save the updated entries back to the processed folder\n",
    "final_entries_df.to_csv(processed_entries_csv, index=False)\n",
    "\n",
    "print(f\"Updated entries saved to {processed_entries_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  puuid  match_count\n",
      "0     -0DVCIv9JiSfm4oB2zIv19NhZH9IWMGk3-n4m6IkxRqBfV...           59\n",
      "1     -1JCcBaL9-zN4y676N7Qm4LDtDq33pNXpfk6pUv33NOGiE...           43\n",
      "2     -1i77tYvBS-0lVcpChDXjWBrd5liH16qJvxKRyNrg51B9S...           59\n",
      "3     -21tZOzPs2yiWOXSLvyZavpds9nVBIKQczbHXdKt3XwsQt...           59\n",
      "4     -2AUTpYzPKKru6-ZE6zFF5VEZFt03pRizZ_1uFYO32mrsT...           59\n",
      "...                                                 ...          ...\n",
      "2371  zqBhjeKnIiiiNEnQzotZ9sIVy18PAgT_hApQnB_TKeDP4v...           59\n",
      "2372  zu0O-Imedl0ONaFOw_HHoCZmIrZgF3mqCkVkwBjjMPmYyH...           59\n",
      "2373  zvFS1lmM0if3Kiss1utrPQNhBke-ryc3b5rjy-Ocfe_prx...           59\n",
      "2374  zxmJuKE0eCnrgCwpg0Q8uQMWbmezhuk6zkw3sTEe_TR9Jk...           59\n",
      "2375  zyMJb5l_r6pBPvYVNkwmaptbveI-uZZrNkmpI1QVrppQgK...           59\n",
      "\n",
      "[2376 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file path to the processed match_ids.csv\n",
    "match_ids_csv = '../data/processed/match_ids.csv'\n",
    "\n",
    "# Ensure the match_ids CSV file exists\n",
    "if not os.path.exists(match_ids_csv):\n",
    "    print(f\"{match_ids_csv} not found.\")\n",
    "    exit()\n",
    "\n",
    "# Load the match_ids CSV into a DataFrame\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "\n",
    "# Count the number of match_ids per PUUID\n",
    "matches_per_puuid = match_ids_df.groupby('puuid')['match_id'].nunique().reset_index(name='match_count')\n",
    "\n",
    "# Display the result\n",
    "print(matches_per_puuid)\n",
    "\n",
    "# Optionally, save the result to a CSV file\n",
    "# matches_per_puuid.to_csv('../data/processed/matches_per_puuid.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   group  puuid_count\n",
      "0   1-10            0\n",
      "1  11-20            0\n",
      "2  21-30            0\n",
      "3  31-40           84\n",
      "4  41-50           83\n",
      "5  51-59           66\n",
      "6    60+         2143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matia\\AppData\\Local\\Temp\\ipykernel_8400\\70686973.py:26: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_counts = matches_per_puuid.groupby('group')['puuid'].count().reset_index(name='puuid_count')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the file path to the processed match_ids.csv\n",
    "match_ids_csv = '../data/processed/match_ids.csv'\n",
    "\n",
    "# Ensure the match_ids CSV file exists\n",
    "if not os.path.exists(match_ids_csv):\n",
    "    print(f\"{match_ids_csv} not found.\")\n",
    "    exit()\n",
    "\n",
    "# Load the match_ids CSV into a DataFrame\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "\n",
    "# Count the number of match_ids per PUUID\n",
    "matches_per_puuid = match_ids_df.groupby('puuid')['match_id'].nunique().reset_index(name='match_count')\n",
    "\n",
    "# Define bins for grouping the number of matches\n",
    "bins = [1, 10, 20, 30, 40, 50, 59, 60]  # Adjust these ranges as needed\n",
    "labels = ['1-10', '11-20', '21-30', '31-40', '41-50', '51-59', '60+']\n",
    "\n",
    "# Assign each account to a group based on the number of matches\n",
    "matches_per_puuid['group'] = pd.cut(matches_per_puuid['match_count'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# Count the number of PUUIDs in each group\n",
    "grouped_counts = matches_per_puuid.groupby('group')['puuid'].count().reset_index(name='puuid_count')\n",
    "\n",
    "# Display the grouped result\n",
    "print(grouped_counts)\n",
    "\n",
    "# Optionally, save the grouped result to a CSV file\n",
    "# grouped_counts.to_csv('../data/processed/grouped_matches_per_puuid.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
