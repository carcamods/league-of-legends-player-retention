{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group sizes before filtering for 100 accounts per group:\n",
      "                          time_group rank  count\n",
      "0          Active Players (1-7 days)    I   1035\n",
      "1          Active Players (1-7 days)   II   1175\n",
      "2          Active Players (1-7 days)  III   1191\n",
      "3          Active Players (1-7 days)   IV   1172\n",
      "4      At Risk of Churn (41-60 days)    I    124\n",
      "5      At Risk of Churn (41-60 days)   II    127\n",
      "6      At Risk of Churn (41-60 days)  III    147\n",
      "7      At Risk of Churn (41-60 days)   IV    130\n",
      "8              Beyond 60 days - Lost    I    218\n",
      "9              Beyond 60 days - Lost   II    149\n",
      "10             Beyond 60 days - Lost  III    127\n",
      "11             Beyond 60 days - Lost   IV    146\n",
      "12      Highly Inactive (29-40 days)    I    105\n",
      "13      Highly Inactive (29-40 days)   II     90\n",
      "14      Highly Inactive (29-40 days)  III     95\n",
      "15      Highly Inactive (29-40 days)   IV     91\n",
      "16  Moderately Inactive (15-28 days)    I    233\n",
      "17  Moderately Inactive (15-28 days)   II    191\n",
      "18  Moderately Inactive (15-28 days)  III    219\n",
      "19  Moderately Inactive (15-28 days)   IV    212\n",
      "20     Slightly Inactive (8-14 days)    I    172\n",
      "21     Slightly Inactive (8-14 days)   II    184\n",
      "22     Slightly Inactive (8-14 days)  III    161\n",
      "23     Slightly Inactive (8-14 days)   IV    181\n",
      "\n",
      "Groups with fewer than 100 accounts:\n",
      "                      time_group rank  count\n",
      "13  Highly Inactive (29-40 days)   II     90\n",
      "14  Highly Inactive (29-40 days)  III     95\n",
      "15  Highly Inactive (29-40 days)   IV     91\n",
      "\n",
      "Duplicate summoner_ids: 0\n",
      "\n",
      "Total selected summoners after filtering: 2376\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define file paths for your CSV data\n",
    "summoner_details_csv = '../data/mass_fetch_8K_accounts/summoner_details.csv'\n",
    "match_details_csv = '../data/mass_fetch_8K_accounts/match_details.csv'\n",
    "entries_csv = '../data/mass_fetch_8K_accounts/entries.csv'\n",
    "match_ids_csv = '../data/mass_fetch_8K_accounts/match_ids.csv'\n",
    "\n",
    "# Ensure all CSV files exist\n",
    "for file in [summoner_details_csv, match_details_csv, entries_csv, match_ids_csv]:\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"{file} not found.\")\n",
    "        exit()\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "summoner_details_df = pd.read_csv(summoner_details_csv)\n",
    "match_details_df = pd.read_csv(match_details_csv)\n",
    "entries_df = pd.read_csv(entries_csv)\n",
    "match_ids_df = pd.read_csv(match_ids_csv)\n",
    "\n",
    "# Convert 'game_creation' to datetime format\n",
    "match_details_df['game_creation_converted'] = pd.to_datetime(match_details_df['game_creation'], unit='ms')\n",
    "\n",
    "# Calculate the difference in days\n",
    "today = pd.Timestamp.now()\n",
    "match_details_df['days_diff'] = (today - match_details_df['game_creation_converted']).dt.days\n",
    "\n",
    "# Define the groups based on days_diff\n",
    "def assign_time_group(days):\n",
    "    if days <= 7:\n",
    "        return 'Active Players (1-7 days)'\n",
    "    elif 8 <= days <= 14:\n",
    "        return 'Slightly Inactive (8-14 days)'\n",
    "    elif 15 <= days <= 28:\n",
    "        return 'Moderately Inactive (15-28 days)'\n",
    "    elif 29 <= days <= 40:\n",
    "        return 'Highly Inactive (29-40 days)'\n",
    "    elif 41 <= days <= 60:\n",
    "        return 'At Risk of Churn (41-60 days)'\n",
    "    else:\n",
    "        return 'Beyond 60 days - Lost'\n",
    "\n",
    "# Apply the function to create the time groups\n",
    "match_details_df['time_group'] = match_details_df['days_diff'].apply(assign_time_group)\n",
    "\n",
    "# Clean the match_details.csv by removing duplicate summoner_ids, keeping the most recent match\n",
    "cleaned_match_details_df = match_details_df.sort_values('game_creation', ascending=False).drop_duplicates(subset='summoner_id', keep='first')\n",
    "\n",
    "# Filter out rows in match_details that correspond to players in summoner_details\n",
    "target_summoners = summoner_details_df['summoner_id'].unique()\n",
    "filtered_match_details = cleaned_match_details_df[cleaned_match_details_df['summoner_id'].isin(target_summoners)].copy()\n",
    "\n",
    "# Joining with the entries DataFrame to get the rank information\n",
    "combined_data = pd.merge(filtered_match_details, entries_df, on='summoner_id', how='left')\n",
    "\n",
    "# Count the number of distinct match_ids for each puuid and filter for puuids with 30 or more matches\n",
    "match_count_per_puuid = match_ids_df.groupby('puuid')['match_id'].nunique().reset_index(name='match_count')\n",
    "puuids_with_30_plus_matches = match_count_per_puuid[match_count_per_puuid['match_count'] >= 30]\n",
    "\n",
    "# Merge to filter only summoners with 30 or more matches\n",
    "filtered_summoner_details = pd.merge(summoner_details_df, puuids_with_30_plus_matches, on='puuid', how='inner')\n",
    "\n",
    "# Filter the combined data based on the filtered summoner details\n",
    "combined_data_filtered = combined_data[combined_data['summoner_id'].isin(filtered_summoner_details['summoner_id'])]\n",
    "\n",
    "# Select exactly 100 accounts per rank and time_group\n",
    "accounts_per_group = 100\n",
    "selected_summoners = []\n",
    "\n",
    "for rank in combined_data_filtered['rank'].unique():\n",
    "    for group in combined_data_filtered['time_group'].unique():\n",
    "        summoners_in_group = combined_data_filtered[(combined_data_filtered['rank'] == rank) & (combined_data_filtered['time_group'] == group)]\n",
    "        if len(summoners_in_group) > accounts_per_group:\n",
    "            selected_summoners += random.sample(list(summoners_in_group['summoner_id'].unique()), accounts_per_group)\n",
    "        else:\n",
    "            selected_summoners += list(summoners_in_group['summoner_id'].unique())\n",
    "\n",
    "# Ensure the list of selected summoners is unique\n",
    "selected_summoners = list(set(selected_summoners))\n",
    "\n",
    "# Check group sizes and duplicates\n",
    "\n",
    "# Group by time_group and rank and check the number of accounts per group\n",
    "grouped_counts = combined_data_filtered.groupby(['time_group', 'rank']).size().reset_index(name='count')\n",
    "print(\"Group sizes before filtering for 100 accounts per group:\")\n",
    "print(grouped_counts)\n",
    "\n",
    "# Check if any group has fewer than 100 accounts\n",
    "print(\"\\nGroups with fewer than 100 accounts:\")\n",
    "print(grouped_counts[grouped_counts['count'] < 100])\n",
    "\n",
    "# Check for duplicate summoner_ids in the final selected accounts\n",
    "selected_summoners_df = pd.DataFrame(selected_summoners, columns=['summoner_id'])\n",
    "duplicate_summoners = selected_summoners_df[selected_summoners_df.duplicated()]\n",
    "\n",
    "print(f\"\\nDuplicate summoner_ids: {len(duplicate_summoners)}\")\n",
    "if not duplicate_summoners.empty:\n",
    "    print(\"List of duplicate summoner_ids:\")\n",
    "    print(duplicate_summoners)\n",
    "\n",
    "# Display the total number of selected summoners\n",
    "print(f\"\\nTotal selected summoners after filtering: {len(selected_summoners)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
